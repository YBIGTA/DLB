{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SOHN\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_data = pd.read_csv(\"train.csv\",header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image data is composed of PIXELS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_data = np.array(my_data, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_pixels = my_data[:,1:]\n",
    "data_labels = my_data[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_images = data_pixels[10].reshape(28,28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 28*28 image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(show_images, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  TrainTestSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(data_pixels, data_labels, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Simple Neural Network\n",
    "\n",
    "- X is (42000,784)\n",
    "- Y is (42000,1)\n",
    "\n",
    "- Declare flow, layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Declare variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "num_iters = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below code implies 3-layer Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(shape= [None, 784], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape =[None], dtype=tf.int32)\n",
    "\n",
    "one_hot_Y = tf.one_hot(Y, depth=10, axis=-1, dtype=tf.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.random_uniform(shape=[784, 400],minval=-0.5, maxval=0.5))\n",
    "b1 = tf.Variable(tf.random_uniform(shape=[400],minval=-0.5, maxval=0.5))\n",
    "z1 = tf.matmul(X, W1)+b1\n",
    "a1 = tf.nn.relu(z1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_uniform(shape=[400, 200],minval=-0.5, maxval=0.5))\n",
    "b2 = tf.Variable(tf.random_uniform(shape=[200], minval=-0.5, maxval=0.5))\n",
    "z2 = tf.matmul(a1,W2)+b2\n",
    "a2 = tf.nn.relu(z2)\n",
    "\n",
    "W3 = tf.Variable(tf.random_uniform(shape=[200, 100],minval=-0.5, maxval=0.5))\n",
    "b3 = tf.Variable(tf.random_uniform(shape=[100],minval=-0.5, maxval=0.5))\n",
    "z3 = tf.matmul(a2,W3)+b3\n",
    "a3 = tf.nn.relu(z3)\n",
    "\n",
    "W4 = tf.Variable(tf.random_uniform(shape=[100, 10],minval=-0.5, maxval=0.5))\n",
    "b4 = tf.Variable(tf.random_uniform(shape=[10],minval=-0.5, maxval=0.5))\n",
    "model = tf.matmul(a3,W4)+b4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define cost and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=one_hot_Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = tf.argmax(model, 1)\n",
    "target = tf.argmax(one_hot_Y, 1)\n",
    "is_correct = tf.equal(prediction, target)\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model and measuring test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 [8.976191] Cost 28125.723\n",
      "정확도 [11.595238] Cost 19551.32\n",
      "정확도 [15.071429] Cost 14331.554\n",
      "정확도 [17.857143] Cost 11953.389\n",
      "정확도 [21.238094] Cost 10631.917\n",
      "정확도 [25.0] Cost 9537.147\n",
      "정확도 [28.547617] Cost 8477.803\n",
      "정확도 [32.190475] Cost 7428.8413\n",
      "정확도 [35.595238] Cost 6461.5923\n",
      "정확도 [39.261906] Cost 5678.5854\n",
      "정확도 [42.785713] Cost 5065.9595\n",
      "정확도 [46.095238] Cost 4510.9385\n",
      "정확도 [49.5] Cost 3965.6267\n",
      "정확도 [52.785713] Cost 3471.2305\n",
      "정확도 [55.595238] Cost 3068.1963\n",
      "정확도 [58.09524] Cost 2750.9023\n",
      "정확도 [60.523808] Cost 2497.3633\n",
      "정확도 [62.7381] Cost 2284.4724\n",
      "정확도 [64.547615] Cost 2108.9868\n",
      "정확도 [66.21429] Cost 1968.5227\n",
      "정확도 [67.35714] Cost 1859.2893\n",
      "정확도 [68.452385] Cost 1774.7828\n",
      "정확도 [69.14285] Cost 1704.8396\n",
      "정확도 [69.71429] Cost 1639.3213\n",
      "정확도 [70.40476] Cost 1572.5707\n",
      "정확도 [71.45238] Cost 1504.2865\n",
      "정확도 [72.309525] Cost 1436.8278\n",
      "정확도 [73.14285] Cost 1373.5024\n",
      "정확도 [73.7619] Cost 1315.8724\n",
      "정확도 [74.547615] Cost 1264.059\n",
      "정확도 [75.309525] Cost 1217.72\n",
      "정확도 [76.2619] Cost 1175.2429\n",
      "정확도 [76.59524] Cost 1135.6174\n",
      "정확도 [77.09524] Cost 1097.9951\n",
      "정확도 [77.52381] Cost 1062.5236\n",
      "정확도 [78.190475] Cost 1029.2518\n",
      "정확도 [78.59524] Cost 998.6993\n",
      "정확도 [79.02381] Cost 971.2531\n",
      "정확도 [79.64285] Cost 946.8851\n",
      "정확도 [79.78571] Cost 925.1383\n",
      "정확도 [80.2381] Cost 904.9435\n",
      "정확도 [80.452385] Cost 885.7373\n",
      "정확도 [80.7619] Cost 867.1255\n",
      "정확도 [80.90476] Cost 848.8143\n",
      "정확도 [81.21429] Cost 830.56995\n",
      "정확도 [81.52381] Cost 812.5866\n",
      "정확도 [81.71429] Cost 795.04315\n",
      "정확도 [81.928566] Cost 778.0907\n",
      "정확도 [82.07143] Cost 761.8851\n",
      "정확도 [82.166664] Cost 746.3718\n",
      "정확도 [82.2619] Cost 731.4734\n",
      "정확도 [82.35715] Cost 717.18805\n",
      "정확도 [82.4762] Cost 703.48035\n",
      "정확도 [82.52381] Cost 690.517\n",
      "정확도 [82.45238] Cost 678.2456\n",
      "정확도 [82.547615] Cost 666.67456\n",
      "정확도 [82.59524] Cost 655.6603\n",
      "정확도 [82.690475] Cost 645.1981\n",
      "정확도 [82.92857] Cost 635.2104\n",
      "정확도 [83.0] Cost 625.5452\n",
      "정확도 [83.21428] Cost 616.0599\n",
      "정확도 [83.38095] Cost 606.7048\n",
      "정확도 [83.45238] Cost 597.38745\n",
      "정확도 [83.64286] Cost 588.1895\n",
      "정확도 [83.71429] Cost 579.1258\n",
      "정확도 [83.78571] Cost 570.2645\n",
      "정확도 [83.85714] Cost 561.697\n",
      "정확도 [84.04762] Cost 553.4107\n",
      "정확도 [84.23809] Cost 545.3938\n",
      "정확도 [84.38095] Cost 537.6337\n",
      "정확도 [84.47619] Cost 530.1083\n",
      "정확도 [84.71429] Cost 522.79944\n",
      "정확도 [84.7619] Cost 515.693\n",
      "정확도 [84.78571] Cost 508.75513\n",
      "정확도 [84.833336] Cost 501.9419\n",
      "정확도 [84.90476] Cost 495.30096\n",
      "정확도 [84.92857] Cost 488.78244\n",
      "정확도 [84.92857] Cost 482.37628\n",
      "정확도 [84.95238] Cost 476.08582\n",
      "정확도 [84.97619] Cost 469.92996\n",
      "정확도 [85.0] Cost 463.88486\n",
      "정확도 [85.04762] Cost 457.9594\n",
      "정확도 [85.09524] Cost 452.1652\n",
      "정확도 [85.14286] Cost 446.48862\n",
      "정확도 [85.21429] Cost 440.90445\n",
      "정확도 [85.309525] Cost 435.41528\n",
      "정확도 [85.38095] Cost 430.021\n",
      "정확도 [85.35714] Cost 424.7531\n",
      "정확도 [85.40476] Cost 419.61206\n",
      "정확도 [85.5] Cost 414.57483\n",
      "정확도 [85.64285] Cost 409.61172\n",
      "정확도 [85.66667] Cost 404.71146\n",
      "정확도 [85.690475] Cost 399.89383\n",
      "정확도 [85.7619] Cost 395.16153\n",
      "정확도 [85.78571] Cost 390.50623\n",
      "정확도 [85.88095] Cost 385.92776\n",
      "정확도 [85.92857] Cost 381.41803\n",
      "정확도 [85.952385] Cost 376.97464\n",
      "정확도 [86.0238] Cost 372.59894\n",
      "정확도 [86.09524] Cost 368.2811\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "cost_NN=[]\n",
    "\n",
    "for iters in range(100):\n",
    "    \n",
    "    costs, _ = sess.run([cost, optimizer], feed_dict={X:X_train, Y:Y_train})\n",
    "    \n",
    "    \n",
    "    #print('예측값:', sess.run(prediction, feed_dict={X: X_test}))\n",
    "    #print('실제값:', sess.run(target, feed_dict={Y: Y_test}))\n",
    "    \n",
    "    acu_rate = sess.run([accuracy*100], feed_dict={X: X_test, Y: Y_test})\n",
    "    print('정확도', acu_rate, 'Cost', costs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습력에 영향을 주는 요소\n",
    "- Optimizer, the number of Layers, complicated model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  학습을 어디서 멈추어야 하는가? Overfitting을 어디서 피해야하는가?\n",
    "- CV를 통해 살펴본 최고 정확도에서의 오차 발생시"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch를 사용하는 이유? 전체 데이터 자체를 Batch 취급할 수 있겠지만, 한 번 도는데 시간이 오래 걸린다. Cost의 흐름을 좀 덜 볼 수도 있겠당"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
